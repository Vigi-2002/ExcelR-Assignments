{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2180b753-2ecc-4966-9347-016da6ff3ae6",
   "metadata": {},
   "source": [
    "# Association Rules(Assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdc4b348-ca56-4697-ab3e-dec2a0a06ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdb9c50-b831-47d7-ab73-0edb043d0e04",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91da0f26-4d8b-4947-8138-0af2e0638e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    antecedents                 consequents   support  \\\n",
      "122             (herb & pepper)               (ground beef)  0.022802   \n",
      "123               (ground beef)             (herb & pepper)  0.022802   \n",
      "204  (spaghetti, mineral water)               (ground beef)  0.024734   \n",
      "209               (ground beef)  (spaghetti, mineral water)  0.024734   \n",
      "114                  (tomatoes)         (frozen vegetables)  0.022609   \n",
      "..                          ...                         ...       ...   \n",
      "94               (french fries)                      (milk)  0.033816   \n",
      "70                       (eggs)               (ground beef)  0.028792   \n",
      "71                (ground beef)                      (eggs)  0.028792   \n",
      "11              (mineral water)                   (burgers)  0.034589   \n",
      "10                    (burgers)             (mineral water)  0.034589   \n",
      "\n",
      "     confidence      lift  \n",
      "122    0.343023  2.525100  \n",
      "123    0.167852  2.525100  \n",
      "204    0.290909  2.141472  \n",
      "209    0.182077  2.141472  \n",
      "114    0.245798  1.892867  \n",
      "..          ...       ...  \n",
      "94     0.175527  1.032216  \n",
      "70     0.138347  1.018417  \n",
      "71     0.211949  1.018417  \n",
      "11     0.115409  1.013996  \n",
      "10     0.303905  1.013996  \n",
      "\n",
      "[216 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel('Online retail.xlsx')\n",
    "\n",
    "# Step 1: Rename the long unnamed column to 'Items'\n",
    "df.columns = ['Items']\n",
    "\n",
    "# Step 2: Convert the comma-separated string of items into a list\n",
    "df['Items'] = df['Items'].apply(lambda x: [item.strip() for item in str(x).split(',') if item.strip() != ''])\n",
    "\n",
    "# Step 3: Drop duplicate transactions\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Step 4: Convert transactions to one-hot encoded format using TransactionEncoder\n",
    "transactions = df['Items'].tolist()\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Step 5: Find frequent itemsets using Apriori\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.02, use_colnames=True)\n",
    "\n",
    "# Step 6: Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "# Step 7: Show the resulting rules with useful metrics\n",
    "result = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
    "print(result.sort_values(by='lift', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7941cc-ecd1-4578-91ab-9d2938b48961",
   "metadata": {},
   "source": [
    "## Association Rule Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "222a6bde-d006-4c5e-9e8a-c85d6d4f6de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          antecedents        consequents   support  confidence      lift\n",
      "44      ('spaghetti')    ('ground beef')  0.041159    0.242045  2.470582\n",
      "45    ('ground beef')      ('spaghetti')  0.041159    0.420118  2.470582\n",
      "77       ('tomatoes')      ('spaghetti')  0.021256    0.383275  2.253920\n",
      "76      ('spaghetti')       ('tomatoes')  0.021256    0.125000  2.253920\n",
      "61           ('soup')  ('mineral water')  0.026280    0.470588  2.153222\n",
      "60  ('mineral water')           ('soup')  0.026280    0.120248  2.153222\n",
      "50      ('olive oil')           ('milk')  0.021836    0.297368  2.140308\n",
      "51           ('milk')      ('olive oil')  0.021836    0.157163  2.140308\n",
      "73      ('olive oil')      ('spaghetti')  0.026473    0.360526  2.120141\n",
      "72      ('spaghetti')      ('olive oil')  0.026473    0.155682  2.120141\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Rename and process the single column\n",
    "df.columns = ['Items']\n",
    "df['Items'] = df['Items'].apply(lambda x: [item.strip() for item in str(x).split(',') if item.strip() != ''])\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Convert to list of lists format for transactions\n",
    "transactions = df['Items'].tolist()\n",
    "\n",
    "# One-hot encode the transactions\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply the Apriori algorithm to find frequent itemsets\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.02, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric='lift', min_threshold=1)\n",
    "\n",
    "# Show rules sorted by lift\n",
    "rules = rules.sort_values(by='lift', ascending=False)\n",
    "rules = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
    "print(rules.head(10))  # Show top 10 interesting rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74ea233-f9ea-46e8-9d69-ab3cb14dfe73",
   "metadata": {},
   "source": [
    "## Extracting patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c946cfb5-987f-4b3b-bcc7-053d40b6dc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               antecedents        consequents   support  \\\n",
      "0                              ('burgers')        (['turkey')  0.014106   \n",
      "16                 ('ground beef', 'milk')      ('spaghetti')  0.010242   \n",
      "20                        ('soup', 'milk')  ('mineral water')  0.010435   \n",
      "2                          ('ground beef')      ('spaghetti')  0.041159   \n",
      "17        ('mineral water', 'ground beef')      ('spaghetti')  0.017391   \n",
      "8                               ('pepper')      ('spaghetti')  0.010821   \n",
      "13  ('mineral water', 'frozen vegetables')      ('spaghetti')  0.010435   \n",
      "4                        ('herb & pepper')      ('spaghetti')  0.010628   \n",
      "15                 ('ground beef', 'milk')  ('mineral water')  0.011594   \n",
      "14      ('spaghetti', 'frozen vegetables')  ('mineral water')  0.010435   \n",
      "\n",
      "    confidence       lift  \n",
      "0     0.948052  11.709233  \n",
      "16    0.456897   2.686863  \n",
      "20    0.574468   2.628534  \n",
      "2     0.420118   2.470582  \n",
      "17    0.416667   2.450284  \n",
      "8     0.414815   2.439394  \n",
      "13    0.409091   2.405733  \n",
      "4     0.404412   2.378217  \n",
      "15    0.517241   2.366688  \n",
      "14    0.482143   2.206091  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Generate frequent itemsets with lower min_support\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# Generate rules with lower confidence\n",
    "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.4)\n",
    "\n",
    "# Relax lift threshold to capture more associations\n",
    "meaningful_rules = rules[(rules['lift'] > 1.0) & (rules['confidence'] >= 0.4)]\n",
    "\n",
    "# Sort and view the rules\n",
    "meaningful_rules = meaningful_rules.sort_values(by='lift', ascending=False)\n",
    "print(meaningful_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688b44f3-bfc2-4c91-86ed-d26e7e8dc0ea",
   "metadata": {},
   "source": [
    "## Analysis and Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b752316-3d54-48f4-8d1e-077c71c1a33b",
   "metadata": {},
   "source": [
    "**1. Spaghetti**\n",
    "\n",
    "    (frozen vegetables, ground beef) ⇒ spaghetti\n",
    "    (eggs, ground beef) ⇒ spaghetti\n",
    "    (chocolate, olive oil) ⇒ spaghetti\n",
    "\n",
    "    Customers who buy basic ingredients like ground beef, eggs, or vegetables are also highly likely to buy spaghetti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68304ff8-0a9f-4460-a8f0-554c2698bed4",
   "metadata": {},
   "source": [
    "**2. Mineral Water is a Frequent Pair**\n",
    "\n",
    "    (soup, milk) ⇒ mineral water\n",
    "    (frozen vegetables, ground beef) ⇒ mineral water\n",
    "\n",
    "    Customers who buy healthy meals also purchase mineral water."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4fe2be-86d8-4257-90c4-e774297873a9",
   "metadata": {},
   "source": [
    "**3. Ground Beef**\n",
    "\n",
    "    (ground beef, milk) ⇒ spaghetti\n",
    "    (chocolate, ground beef) ⇒ spaghetti\n",
    "    (ground beef, mineral water) ⇒ spaghetti\n",
    "\n",
    "    Whenever ground beef is bought, people tend to buy several other items with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30a8f91-a882-4c66-b28d-0fd5b48f1d1b",
   "metadata": {},
   "source": [
    "## Interview Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ac02ca-935d-4a1b-a5d6-6406795e99a6",
   "metadata": {},
   "source": [
    "#### Q.\tWhat is lift and why is it important in Association rules?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46fbe99-7894-4dfd-9c24-d65c726848d4",
   "metadata": {},
   "source": [
    "Lift tells you how much more likely two items are to be bought together than separately by chance.\n",
    "\n",
    "Lift shows how interesting or useful a rule is.\n",
    "\n",
    "A high lift means: \"If someone buys X, they're way more likely to also buy Y — not just by chance.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bf8816-fde0-474e-98c5-fe120e0d5bd7",
   "metadata": {},
   "source": [
    "#### Q.\tWhat is support and Confidence. How do you calculate them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d7238a-6927-43e7-b4b1-1be5b203fb31",
   "metadata": {},
   "source": [
    "**Support:**\n",
    "    Support tells you how often an item or set of items appears in all transactions.\n",
    "\n",
    "    eg- 100 transactions,\n",
    "        15 of those include milk\n",
    "        Support(milk) = 15 / 100 = 0.15 (or 15%)\n",
    "        **Support(X) = transactions with X / total**\n",
    "\n",
    "**Confidence:**\n",
    "    Confidence tells you how often Y is bought when X is bought.\n",
    "    \n",
    "    \"If someone buys X, how confident are we that they also buy Y?\"\n",
    "    \n",
    "    eg- 15 people bought milk\n",
    "        10 of them also bought bread\n",
    "        Confidence(milk ⇒ bread) = 10 / 15 = 0.67 (or 67%)\n",
    "        **Confidence(X ⇒ Y) = Support(X and Y) / Support(X)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923df4c-9492-4d52-b49a-20be810c6ab5",
   "metadata": {},
   "source": [
    "#### Q. What are some limitations or challenges of Association rules mining?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4437b1f-f510-443b-a6e3-6dd8d561b024",
   "metadata": {},
   "source": [
    "The limitations include:\n",
    "\n",
    "**1. Too Many Rules:**\n",
    "\n",
    "    Even with small datasets, you can generate thousands of rules.\n",
    "\n",
    "**2. Not All Rules Are Meaningful:**\n",
    "\n",
    "    Just because two products are bought together doesn’t mean there’s a useful or causal relationship.\n",
    "\n",
    "**3. Ignores Item Quantities:**\n",
    "\n",
    "    Association rules typically only consider whether an item was bought or not\n",
    "\n",
    "**4. No Time Factor:**\n",
    "\n",
    "    Rules do not consider the order or timing of purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a88db49-bf83-41d7-953f-ac983f15f98c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
